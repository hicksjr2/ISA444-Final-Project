{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING"
      ],
      "metadata": {
        "id": "JTvK4GyoLNHJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NisKdNggIb_",
        "outputId": "c01862c7-8663-46ec-932f-abdfd6678a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! Saved downsampled_df.csv\n",
            "Number of series: 40\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train[\"Date\"] = pd.to_datetime(train[\"Date\"])\n",
        "\n",
        "# create Store_Dept series ID\n",
        "train[\"series_id\"] = train[\"Store\"].astype(str) + \"_\" + train[\"Dept\"].astype(str)\n",
        "\n",
        "# select top 40 highest-volume series\n",
        "top_series = (\n",
        "    train.groupby(\"series_id\")[\"Weekly_Sales\"]\n",
        "         .sum()\n",
        "         .sort_values(ascending=False)\n",
        "         .head(40)\n",
        "         .index\n",
        ")\n",
        "\n",
        "train_ds = train[train[\"series_id\"].isin(top_series)].copy()\n",
        "\n",
        "# convert to Nixtla panel format\n",
        "Y_df = (\n",
        "    train_ds\n",
        "    .rename(columns={\n",
        "        \"series_id\": \"unique_id\",\n",
        "        \"Date\": \"ds\",\n",
        "        \"Weekly_Sales\": \"y\"\n",
        "    })\n",
        "    [[\"unique_id\", \"ds\", \"y\"]]\n",
        "    .sort_values([\"unique_id\", \"ds\"])\n",
        ")\n",
        "\n",
        "# save as csv file\n",
        "Y_df.to_csv(\"downsampled_df.csv\", index=False)\n",
        "\n",
        "print(\"Done! Saved downsampled_df.csv\")\n",
        "print(\"Number of series:\", Y_df[\"unique_id\"].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "Y_df = pd.read_csv(\"downsampled_df.csv\")\n",
        "Y_df[\"ds\"] = pd.to_datetime(Y_df[\"ds\"])  # important\n",
        "\n",
        "print(Y_df.head())\n",
        "print(\"Number of series:\", Y_df[\"unique_id\"].nunique())\n"
      ],
      "metadata": {
        "id": "9i_EVoo8jMvZ",
        "outputId": "754a837c-dc8a-4508-e045-c904e511b412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  unique_id         ds          y\n",
            "0      10_2 2010-02-05  123952.48\n",
            "1      10_2 2010-02-12  119209.48\n",
            "2      10_2 2010-02-19  121430.80\n",
            "3      10_2 2010-02-26  120292.15\n",
            "4      10_2 2010-03-05  113163.91\n",
            "Number of series: 40\n"
          ]
        }
      ]
    }
  ]
}